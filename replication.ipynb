{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d910086-2d54-42ea-aa33-7b9373e247ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>budget</th>\n",
       "      <th>runtime</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>GDP</th>\n",
       "      <th>INFLATION</th>\n",
       "      <th>INTEREST_RATE</th>\n",
       "      <th>director_past_avg_rev</th>\n",
       "      <th>Action</th>\n",
       "      <th>Adventure</th>\n",
       "      <th>...</th>\n",
       "      <th>overview_pca_40</th>\n",
       "      <th>overview_pca_41</th>\n",
       "      <th>overview_pca_42</th>\n",
       "      <th>overview_pca_43</th>\n",
       "      <th>overview_pca_44</th>\n",
       "      <th>overview_pca_45</th>\n",
       "      <th>overview_pca_46</th>\n",
       "      <th>overview_pca_47</th>\n",
       "      <th>overview_pca_48</th>\n",
       "      <th>overview_pca_49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7500000</td>\n",
       "      <td>103.0</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15048.971</td>\n",
       "      <td>1.640043</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017044</td>\n",
       "      <td>0.037198</td>\n",
       "      <td>-0.064563</td>\n",
       "      <td>0.020676</td>\n",
       "      <td>0.065429</td>\n",
       "      <td>-0.048382</td>\n",
       "      <td>-0.128791</td>\n",
       "      <td>0.075139</td>\n",
       "      <td>0.075847</td>\n",
       "      <td>0.083124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12500000</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8073.122</td>\n",
       "      <td>2.931204</td>\n",
       "      <td>5.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.021330</td>\n",
       "      <td>-0.041371</td>\n",
       "      <td>-0.014677</td>\n",
       "      <td>0.004924</td>\n",
       "      <td>0.091164</td>\n",
       "      <td>-0.043685</td>\n",
       "      <td>-0.068544</td>\n",
       "      <td>0.022891</td>\n",
       "      <td>-0.124368</td>\n",
       "      <td>0.038199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1500000</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>18295.019</td>\n",
       "      <td>0.118627</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.167959</td>\n",
       "      <td>-0.025022</td>\n",
       "      <td>-0.107306</td>\n",
       "      <td>-0.030180</td>\n",
       "      <td>0.072310</td>\n",
       "      <td>-0.044618</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>0.098723</td>\n",
       "      <td>-0.050129</td>\n",
       "      <td>0.041407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6858.559</td>\n",
       "      <td>2.951657</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036006</td>\n",
       "      <td>0.053802</td>\n",
       "      <td>-0.069026</td>\n",
       "      <td>-0.111518</td>\n",
       "      <td>0.145948</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.020099</td>\n",
       "      <td>-0.124613</td>\n",
       "      <td>0.001808</td>\n",
       "      <td>-0.000265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26000000</td>\n",
       "      <td>94.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12217.196</td>\n",
       "      <td>2.677237</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052132</td>\n",
       "      <td>-0.067214</td>\n",
       "      <td>-0.096312</td>\n",
       "      <td>0.115198</td>\n",
       "      <td>-0.066432</td>\n",
       "      <td>0.038178</td>\n",
       "      <td>-0.016772</td>\n",
       "      <td>-0.142391</td>\n",
       "      <td>-0.134119</td>\n",
       "      <td>0.107727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     budget  runtime    Year  Month        GDP  INFLATION  INTEREST_RATE  \\\n",
       "0   7500000    103.0  2010.0    1.0  15048.971   1.640043           0.73   \n",
       "1  12500000     99.0  1996.0    1.0   8073.122   2.931204           5.02   \n",
       "2   1500000     97.0  2015.0    3.0  18295.019   0.118627           0.77   \n",
       "3   3000000     87.0  1993.0    8.0   6858.559   2.951657           3.00   \n",
       "4  26000000     94.0  2004.0    7.0  12217.196   2.677237           2.40   \n",
       "\n",
       "   director_past_avg_rev  Action  Adventure  ...  overview_pca_40  \\\n",
       "0                    0.0       0          0  ...        -0.017044   \n",
       "1                    0.0       0          0  ...        -0.021330   \n",
       "2                    0.0       0          0  ...         0.167959   \n",
       "3                    0.0       0          0  ...         0.036006   \n",
       "4                    0.0       0          0  ...        -0.052132   \n",
       "\n",
       "   overview_pca_41  overview_pca_42  overview_pca_43  overview_pca_44  \\\n",
       "0         0.037198        -0.064563         0.020676         0.065429   \n",
       "1        -0.041371        -0.014677         0.004924         0.091164   \n",
       "2        -0.025022        -0.107306        -0.030180         0.072310   \n",
       "3         0.053802        -0.069026        -0.111518         0.145948   \n",
       "4        -0.067214        -0.096312         0.115198        -0.066432   \n",
       "\n",
       "   overview_pca_45  overview_pca_46  overview_pca_47  overview_pca_48  \\\n",
       "0        -0.048382        -0.128791         0.075139         0.075847   \n",
       "1        -0.043685        -0.068544         0.022891        -0.124368   \n",
       "2        -0.044618         0.007216         0.098723        -0.050129   \n",
       "3         0.000020        -0.020099        -0.124613         0.001808   \n",
       "4         0.038178        -0.016772        -0.142391        -0.134119   \n",
       "\n",
       "   overview_pca_49  \n",
       "0         0.083124  \n",
       "1         0.038199  \n",
       "2         0.041407  \n",
       "3        -0.000265  \n",
       "4         0.107727  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"merged_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27e6155-33d8-488f-8dce-16d923b5d0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df['revenue']\n",
    "X = df.drop('revenue', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22b2c4f-269d-47ef-8952-c3d365c58525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:  {'R²': 0.5775274736241938, 'RMSE': 1.3828040390485258e+16, 'MAE': 73385861.51913144}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "class LinearModel:\n",
    "    def __init__(self):\n",
    "        # Pipeline ensures automatic normalization\n",
    "        self.model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"reg\", LinearRegression())\n",
    "        ])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Train the normalized linear regression model.\"\"\"\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Predict outputs for new inputs.\"\"\"\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Compute performance metrics.\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        metrics = {\n",
    "            \"R²\": r2_score(y, y_pred),\n",
    "            \"RMSE\": mean_squared_error(y, y_pred),\n",
    "            \"MAE\": mean_absolute_error(y, y_pred)\n",
    "        }\n",
    "        return metrics\n",
    "    \n",
    "    def summary(self, feature_names=None):\n",
    "        \"\"\"Display learned coefficients after scaling.\"\"\"\n",
    "        reg = self.model.named_steps[\"reg\"]\n",
    "\n",
    "        if feature_names is None:\n",
    "            feature_names = [f\"f{i}\" for i in range(len(reg.coef_))]\n",
    "        \n",
    "        print(\"Intercept:\", reg.intercept_)\n",
    "        print(\"\\nCoefficients:\")\n",
    "        for name, coef in zip(feature_names, reg.coef_):\n",
    "            print(f\"{name:25s} {coef:.4f}\")\n",
    "\n",
    "lm = LinearModel()\n",
    "lm.fit(X_train,y_train)\n",
    "#lm.summary()\n",
    "preds = lm.predict(X_test)\n",
    "\n",
    "metrics = lm.evaluate(X_test,y_test)\n",
    "print(\"Model Performance: \", metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37dbce-96ea-46be-9dba-1f816e5590c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "class XGBModel:\n",
    "    def __init__(self):\n",
    "        self.model = XGBRegressor(\n",
    "            n_estimators=500,\n",
    "            learning_rate=0.05,\n",
    "            max_depth=6,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            objective=\"reg:squarederror\",\n",
    "            random_state=42,\n",
    "            tree_method=\"hist\"\n",
    "        )\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        return {\"R²\": r2, \"RMSE\": rmse, \"MAE\": mae}\n",
    "    \n",
    "    def summary(self, feature_names=None, top_k=20):\n",
    "        importances = self.model.feature_importances_\n",
    "        if feature_names is None:\n",
    "            feature_names = [f\"f{i}\" for i in range(len(importances))]\n",
    "        \n",
    "        feats = list(zip(feature_names, importances))\n",
    "        feats = sorted(feats, key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"Top {top_k} features by importance:\")\n",
    "        for name, imp in feats[:top_k]:\n",
    "            print(f\"{name}: {imp:.4f}\")\n",
    "\n",
    "# Training with hyperparameter tuning & cross-validation \n",
    "xgb = XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\"\n",
    ")\n",
    "\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_dist = {\n",
    "    \"n_estimators\":     [400, 700, 1000, 1300],\n",
    "    \"max_depth\":        [3, 4, 5, 6],\n",
    "    \"learning_rate\":    [0.01, 0.03, 0.05, 0.1],   \n",
    "    \"subsample\":        [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"min_child_weight\": [1, 3, 5, 10],\n",
    "    \"reg_alpha\":        [0, 0.01, 0.1, 1.0],\n",
    "    \"reg_lambda\":       [0.5, 1, 5, 10],\n",
    "    \"gamma\":            [0, 0.1, 0.3, 1.0],        \n",
    "}\n",
    "\n",
    "# 3-fold CV (randomized)\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=100,                      \n",
    "    scoring=\"neg_root_mean_squared_error\",\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", random_search.best_params_)\n",
    "print(\"Best CV RMSE:\", -random_search.best_score_)\n",
    "\n",
    "# evaluate best model on test \n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgb.predict(X_test)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "print(\"Test R²:  \", r2)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test MAE: \", mae)\n",
    "\n",
    "# see top 20 most important features \n",
    "importances = best_xgb.feature_importances_\n",
    "feat_importance = sorted(\n",
    "    zip(X.columns, importances),\n",
    "    key=lambda x: x[1],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "print(\"\\nTop 20 features:\")\n",
    "for name, imp in feat_importance[:20]:\n",
    "    print(f\"{name:30s} {imp:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a0b22-df19-48e8-9841-e2b2c47fc371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get top 20 (already sorted above)\n",
    "top20 = feat_importance[:20]\n",
    "\n",
    "# Unzip into two lists\n",
    "feature_names, importance_values = zip(*top20)\n",
    "\n",
    "# Reverse for horizontal bar plot (largest at top)\n",
    "feature_names = feature_names[::-1]\n",
    "importance_values = importance_values[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(feature_names, importance_values)\n",
    "plt.xlabel(\"Feature Importance\", fontsize=12)\n",
    "plt.title(\"Top 20 Most Important Features (XGBoost)\", fontsize=14)\n",
    "plt.grid(axis=\"x\", linestyle=\"--\", alpha=0.4)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904d8979-3a26-4939-ad0b-094c94d779ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "class PolyRegModel:\n",
    "    def __init__(self, degree=2, alpha=1.0):\n",
    "        \"\"\"\n",
    "        degree: polynomial degree (e.g., 2 for quadratic, 3 for cubic)\n",
    "        alpha:  L2 regularization strength (Ridge); alpha=0 ≈ plain linear reg\n",
    "        \"\"\"\n",
    "        self.degree = degree\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        self.model = Pipeline([\n",
    "            (\"poly\", PolynomialFeatures(degree=self.degree, include_bias=False)),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"reg\", Ridge(alpha=self.alpha))\n",
    "        ])\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        y_pred = self.predict(X)\n",
    "        r2 = r2_score(y, y_pred)\n",
    "        rmse = mean_squared_error(y, y_pred, squared=False)\n",
    "        mae = mean_absolute_error(y, y_pred)\n",
    "        return {\"R²\": r2, \"RMSE\": rmse, \"MAE\": mae}\n",
    "    \n",
    "    @staticmethod\n",
    "    def tune(X, y, cv=3, n_iter=20, random_state=42):\n",
    "\n",
    "        # Base pipeline \n",
    "        base_pipe = Pipeline([\n",
    "            (\"poly\", PolynomialFeatures(include_bias=False)),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"reg\", Ridge())\n",
    "        ])\n",
    "\n",
    "        param_dist = {\n",
    "            \"poly__degree\": [1, 2, 3, 4, 5],                      # try different polynomial degrees\n",
    "            \"reg__alpha\":  [0.0, 0.01, 0.05, 0.75, 0.1, 0.2, 1],  # ridge strength\n",
    "        }\n",
    "\n",
    "        search = RandomizedSearchCV(\n",
    "            estimator=base_pipe,\n",
    "            param_distributions=param_dist,\n",
    "            n_iter=n_iter,\n",
    "            scoring=\"neg_root_mean_squared_error\",\n",
    "            cv=cv,\n",
    "            verbose=1,\n",
    "            n_jobs=-1,\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        search.fit(X, y)\n",
    "\n",
    "        # get best params\n",
    "        best_degree = search.best_params_[\"poly__degree\"]\n",
    "        best_alpha = search.best_params_[\"reg__alpha\"]\n",
    "\n",
    "        # Create a PolyRegModel with these and plug in best pipeline\n",
    "        best_model = PolyRegModel(degree=best_degree, alpha=best_alpha)\n",
    "        best_model.model = search.best_estimator_\n",
    "\n",
    "        return best_model, search\n",
    "    \n",
    "\n",
    "# Hyperparameter tuning on the train set\n",
    "best_model, search = PolyRegModel.tune(X_train, y_train)\n",
    "\n",
    "print(\"Best params:\", search.best_params_)\n",
    "print(\"Best CV RMSE:\", -search.best_score_)\n",
    "\n",
    "# Evaluate on test set\n",
    "metrics = best_model.evaluate(X_test, y_test)\n",
    "print(\"Test R²: \", metrics[\"R²\"])\n",
    "print(\"Test RMSE:\", metrics[\"RMSE\"])\n",
    "print(\"Test MAE:\", metrics[\"MAE\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
